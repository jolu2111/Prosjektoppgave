{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation=nn.Tanh\n",
    "\n",
    "class pinn(nn.Module):\n",
    "    def __init__(self, hidden_size=16,hidden_layers=4):\n",
    "        super(pinn, self).__init__()\n",
    "        layers= [nn.Linear(2, hidden_size), activation()]\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(activation())\n",
    "        layers.append(nn.Linear(hidden_size, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "#Defining changeable parameters:\n",
    "epochs=1000\n",
    "num_training_points=1000\n",
    "\n",
    "model=pinn(hidden_size=20, hidden_layers=3) # to be used for evaluating u at boundaries and inside the domain\n",
    "\n",
    "# Changable parameters:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #Using the Adam optimizer\n",
    "mse_loss = nn.MSELoss() #Using the Mean Squared Error loss function\n",
    "\n",
    "#Defining PDE\n",
    "def laplace_residual(u, x, y):\n",
    "    # Compute first derivatives with respect to x and y\n",
    "    du_dx = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    du_dy = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    \n",
    "    # Compute second derivatives\n",
    "    d2u_dx2 = torch.autograd.grad(du_dx, x, grad_outputs=torch.ones_like(du_dx), create_graph=True)[0]\n",
    "    d2u_dy2 = torch.autograd.grad(du_dy, y, grad_outputs=torch.ones_like(du_dy), create_graph=True)[0]\n",
    "    \n",
    "    # Laplace residual\n",
    "    laplace_residual = torch.mean((d2u_dx2 + d2u_dy2)**2)\n",
    "    return laplace_residual\n",
    "\n",
    "#_______________________________________________________________________________________\n",
    "#Vertical boundary condition A, vertical_a (v_a) paramteres:\n",
    "v_a_x=0   #x-coordinate of the vertical boundary\n",
    "v_a_num_points=100  #Number of points on the vertical boundary\n",
    "v_a_head=0  #Dirichtlet value of the boundary condition\n",
    "v_a_y_start=0   #Starting y-coordinate of the vertical boundary\n",
    "v_a_y_end=1     #Ending y-coordinate of the vertical boundary\n",
    "\n",
    "#Generating tensors for the vertical boundary condition A\n",
    "v_a_x_points=torch.full((v_a_num_points,1),v_a_x)\n",
    "v_a_y_points = torch.linspace(v_a_y_start, v_a_y_end, v_a_num_points).reshape(-1,1) #Should maybe change this to rand()?\n",
    "v_a_boundary_points=torch.cat((v_a_x_points,v_a_y_points),dim=1)\n",
    "v_a_boundary_target= torch.full((v_a_num_points,1),v_a_head)  #This may have to be in a list?\n",
    "\n",
    "#Vertical boundary condition B, vertical_b (v_b) paramteres:\n",
    "v_b_x=1   #x-coordinate of the vertical boundary\n",
    "v_b_num_points=100  #Number of points on the vertical boundary\n",
    "v_b_head=1  #Dirichtlet value of the boundary condition\n",
    "v_b_y_start=0   #Starting y-coordinate of the vertical boundary\n",
    "v_b_y_end=1     #Ending y-coordinate of the vertical boundary\n",
    "\n",
    "#Generating tensors for the vertical boundary condition B\n",
    "v_b_x_points=torch.full((v_b_num_points,1),v_b_x)\n",
    "v_b_y_points = torch.linspace(v_b_y_start, v_b_y_end, v_b_num_points).reshape(-1,1) #Should maybe change this to rand()?\n",
    "v_b_boundary_points=torch.cat((v_b_x_points,v_b_y_points),dim=1)\n",
    "v_b_boundary_target= torch.full((v_b_num_points,1),v_b_head)  #This may have to be in a list?\n",
    "\n",
    "#Horizontal boundary condition A, horizontal_a (h_a) paramteres:\n",
    "\n",
    "\n",
    "#Boundary conditions:\n",
    "def loss_vertical_boundary(model,type,boundary_points,boundary_target):\n",
    "    if type==\"dirichlet\":\n",
    "        u_pred = model(boundary_points)\n",
    "        # boundary_target= torch.full((num_boundary_points,1),head)  ##could be torch and inside for dynamic boundary points.\n",
    "        boundary_residual= u_pred-boundary_target\n",
    "        return torch.mean((boundary_residual)**2)\n",
    "    elif type==\"neumann\":\n",
    "\n",
    "        return 'nan'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid boundary condition type\")\n",
    "\n",
    "\n",
    "# Creating domain points\n",
    "x = torch.rand((num_training_points,1),requires_grad=True) #Need to be changed to the actual domain\n",
    "y = torch.rand((num_training_points,1),requires_grad=True) #Need to be changed to the actual domain\n",
    "train_points=torch.cat([x,y],1) \n",
    "\n",
    "#Training loop:\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad() #Have to zero the gradients at the start of each epoch\n",
    "    \n",
    "    u_pred=model(train_points)\n",
    "    \n",
    "    #losses\n",
    "    loss_laplace=laplace_residual(u_pred,x,y)\n",
    "    #Boundary condition loss\n",
    "    loss_boundary_a=loss_vertical_boundary(model,\"dirichlet\",v_a_boundary_points,v_a_boundary_target)\n",
    "    loss_boundary_b=loss_vertical_boundary(model,\"dirichlet\",v_b_boundary_points,v_b_boundary_target)\n",
    "\n",
    "    loss=loss_laplace + loss_boundary_a+loss_boundary_b\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network for the Physics-Informed Neural Network (PINN)\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, hidden_dim=20, num_hidden_layers=3):\n",
    "        super(PINN, self).__init__()\n",
    "        layers = [nn.Linear(2, hidden_dim), nn.Tanh()]\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(hidden_dim, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Physics-Informed Loss Function\n",
    "def laplace_loss(model, coords):\n",
    "    u = model(coords)\n",
    "    grads = torch.autograd.grad(u, coords, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(grads[:, 0], coords, grad_outputs=torch.ones_like(grads[:, 0]), create_graph=True)[0][:, 0]\n",
    "    u_yy = torch.autograd.grad(grads[:, 1], coords, grad_outputs=torch.ones_like(grads[:, 1]), create_graph=True)[0][:, 1]\n",
    "    return torch.mean((u_xx + u_yy) ** 2)\n",
    "\n",
    "# Boundary conditions\n",
    "def boundary_loss(model, coords, target):\n",
    "    u_pred = model(coords)\n",
    "    return torch.mean((u_pred - target) ** 2)\n",
    "\n",
    "# Generate coordinates and boundary conditions\n",
    "def generate_data(num_domain_points=1000, num_boundary_points=100):\n",
    "    # Domain points\n",
    "    x = torch.rand((num_domain_points, 1), requires_grad=True)\n",
    "    y = torch.rand((num_domain_points, 1), requires_grad=True)\n",
    "    domain_points = torch.cat([x, y], dim=1)\n",
    "\n",
    "    # Boundary points and target values\n",
    "    boundary_points = []\n",
    "    target_values = []\n",
    "\n",
    "    # Boundary conditions for a square domain: [0, 1] x [0, 1]\n",
    "    \n",
    "    # u(x, 0) = x and u(x, 1) = x\n",
    "    x_boundary = torch.rand((num_boundary_points, 1))\n",
    "    boundary_points.append(torch.cat([x_boundary, torch.zeros((num_boundary_points, 1))], dim=1))  # y = 0\n",
    "    target_values.append(x_boundary)\n",
    "    boundary_points.append(torch.cat([x_boundary, torch.ones((num_boundary_points, 1))], dim=1))   # y = 1\n",
    "    target_values.append(x_boundary)\n",
    "\n",
    "    # u(0, y) = 0\n",
    "    y_boundary = torch.rand((num_boundary_points, 1))\n",
    "    boundary_points.append(torch.cat([torch.zeros((num_boundary_points, 1)), y_boundary], dim=1))\n",
    "    target_values.append(torch.zeros((num_boundary_points, 1)))\n",
    "\n",
    "    # u(1, y) = 1\n",
    "    boundary_points.append(torch.cat([torch.ones((num_boundary_points, 1)), y_boundary], dim=1))\n",
    "    target_values.append(torch.ones((num_boundary_points, 1)))\n",
    "\n",
    "    boundary_points = torch.cat(boundary_points, dim=0).requires_grad_(True)\n",
    "    target_values = torch.cat(target_values, dim=0)\n",
    "\n",
    "    return domain_points, boundary_points, target_values\n",
    "\n",
    "# Initialize model, optimizer, and training loop\n",
    "model = PINN(hidden_dim=20, num_hidden_layers=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Generate data\n",
    "domain_points, boundary_points, boundary_targets = generate_data()\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute losses\n",
    "    domain_loss = laplace_loss(model, domain_points)\n",
    "    boundary_loss_val = boundary_loss(model, boundary_points, boundary_targets)\n",
    "    \n",
    "    # Total loss\n",
    "    loss = domain_loss + boundary_loss_val\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Logging\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch}, Total Loss: {loss.item()}, Domain Loss: {domain_loss.item()}, Boundary Loss: {boundary_loss_val.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
