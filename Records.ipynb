{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "u=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)  # Python random module\n",
    "    np.random.seed(seed)  # Numpy random module\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU\n",
    "    torch.cuda.manual_seed_all(seed)  # All GPUs (if multiple)\n",
    "\n",
    "# Set the seed\n",
    "set_seed(123)\n",
    "\n",
    "# Define the neural network for the Physics-Informed Neural Network (PINN)\n",
    "class pinn(nn.Module):\n",
    "    def __init__(self, hidden_size=20, hidden_layers=3):\n",
    "        super(pinn, self).__init__()\n",
    "        layers = [nn.Linear(2, hidden_size), nn.Tanh()]\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(hidden_size, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def laplace_residual(model, coords):\n",
    "    u = model(coords)\n",
    "    grads = torch.autograd.grad(u, coords, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(grads[:, 0], coords, grad_outputs=torch.ones_like(grads[:, 0]), create_graph=True)[0][:, 0]\n",
    "    u_yy = torch.autograd.grad(grads[:, 1], coords, grad_outputs=torch.ones_like(grads[:, 1]), create_graph=True)[0][:, 1]\n",
    "    return torch.mean((u_xx + u_yy) ** 2)\n",
    "\n",
    "#Boundary conditions:\n",
    "def loss_dirichlet_boundary(model,boundary_points,boundary_target):\n",
    "    u_pred = model(boundary_points)\n",
    "    boundary_residual= u_pred-boundary_target\n",
    "    return torch.mean((boundary_residual)**2)\n",
    "\n",
    "def loss_neumann_boundary(model,boundary_points,axis='horizontal'):\n",
    "    u_pred = model(boundary_points)\n",
    "    u_grad= torch.autograd.grad(u_pred,boundary_points,grad_outputs=torch.ones_like(u_pred),create_graph=True)[0] #This is the gradient of u \n",
    "    if axis=='vertical':\n",
    "        u_x = u_grad[:,0] # This is the x-component of the gradient of u\n",
    "        return torch.mean((u_x)**2)\n",
    "    elif axis=='horizontal':\n",
    "        u_y = u_grad[:,1] # This is the y-component of the gradient of u\n",
    "        return torch.mean((u_y)**2)\n",
    "\n",
    "# Function to create boundary points\n",
    "def create_boundary_points(axis, place, start, end, num_points, head=None):\n",
    "    line_points = torch.full((num_points, 1), place)\n",
    "    place_points = start + (end - start) * torch.rand(num_points, 1)\n",
    "    \n",
    "    if axis == 'vertical':\n",
    "        boundary_points = torch.cat([line_points, place_points], dim=1)\n",
    "    elif axis == 'horizontal':\n",
    "        boundary_points = torch.cat([place_points, line_points], dim=1)\n",
    "\n",
    "    # Only return targets if head value is provided (for Dirichlet conditions)\n",
    "    if head is not None:\n",
    "        boundary_targets = torch.full((num_points, 1), head, dtype=torch.float)\n",
    "        return boundary_points, boundary_targets\n",
    "    else:\n",
    "        return boundary_points\n",
    "    \n",
    "def plot_losses(epochs, laplace_losses, dirichlet_losses, neumann_losses, total_losses):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(epochs, laplace_losses, label=\"Laplace Loss\")\n",
    "    plt.plot(epochs, dirichlet_losses, label=\"Dirichlet Loss\")\n",
    "    plt.plot(epochs, total_losses, label=\"Total Loss\")\n",
    "    plt.plot(epochs, neumann_losses, label=\"Neumann Loss\")\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss value\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#_____________________________________________________________________________________________________________\n",
    "\n",
    "# Boundary points and targets storage\n",
    "boundary_points_dirichlet = []\n",
    "boundary_target_dirichlet = []\n",
    "boundary_points_neumann = []\n",
    "\n",
    "# Dirichlet boundary conditions\n",
    "dirichlet_boundaries = [\n",
    "    ('vertical', 0, 0, 1, 1000, 0),  # Left boundary\n",
    "    ('vertical', 1, 0, 1, 1000, 1),  # Right boundary\n",
    "    # ('horizontal', 0, 0, 1, 100, 1),  # Bottom boundary\n",
    "    # ('horizontal', 1, 0, 1, 100, 0)   # Top boundary\n",
    "]\n",
    "\n",
    "for axis, place, start, end, num_points, head in dirichlet_boundaries:\n",
    "    boundary_points, boundary_targets = create_boundary_points(axis, place, start, end, num_points, head)\n",
    "    boundary_points_dirichlet.append(boundary_points)\n",
    "    boundary_target_dirichlet.append(boundary_targets)\n",
    "\n",
    "# Concatenate Dirichlet boundary points and targets\n",
    "boundary_points_dirichlet = torch.cat(boundary_points_dirichlet, dim=0).requires_grad_(True)\n",
    "boundary_target_dirichlet = torch.cat(boundary_target_dirichlet, dim=0)\n",
    "\n",
    "# Neumann boundary conditions\n",
    "neumann_boundaries = [\n",
    "    # ('vertical', 0, 0, 1, 100),  # Left boundary\n",
    "    # ('vertical', 1, 0, 1, 100),  # Right boundary\n",
    "    ('horizontal', 0, 0, 1, 100),  # Bottom boundary\n",
    "    ('horizontal', 1, 0, 1, 100)   # Top boundary\n",
    "]\n",
    "\n",
    "for axis, place, start, end, num_points in neumann_boundaries:\n",
    "    boundary_points = create_boundary_points(axis, place, start, end, num_points)\n",
    "    boundary_points_neumann.append(boundary_points)\n",
    "\n",
    "# Concatenate Neumann boundary points\n",
    "boundary_points_neumann = torch.cat(boundary_points_neumann, dim=0).requires_grad_(True)\n",
    "\n",
    "# Creating domain points\n",
    "num_domain_points=1000\n",
    "x = torch.rand((num_domain_points,1),requires_grad=True) #Need to be changed to the actual domain\n",
    "y = torch.rand((num_domain_points,1),requires_grad=True) #Need to be changed to the actual domain\n",
    "train_points=torch.cat([x,y],dim=1) \n",
    "\n",
    "# Initialize lists to store losses and plot\n",
    "laplace_losses = []\n",
    "dirichlet_losses = []\n",
    "neumann_losses = []\n",
    "total_losses = []\n",
    "epochs_recorded = []\n",
    "\n",
    "\n",
    "\n",
    "#Defining changeable parameters:\n",
    "model=pinn(hidden_size=64, hidden_layers=3) # to be used for evaluating u at boundaries and inside the domain\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1, max_iter=20) #Using the Adam optimizer\n",
    "lambda_laplace, lambda_dirichlet, lambda_neumann = 1,1,1  #Weights for the losses\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=50, verbose=True)\n",
    "epochs=101\n",
    "\n",
    "#Training loop:\n",
    "for epoch in range(epochs):\n",
    "    # optimizer.zero_grad() #Have to zero the gradients at the start of each epoch\n",
    "\n",
    "    \n",
    "    # Backward pass\n",
    "    # loss.backward()\n",
    "    # Update \n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss_laplace = laplace_residual(model, train_points)\n",
    "        boundary_loss_dirichlet = loss_dirichlet_boundary(model, boundary_points_dirichlet, boundary_target_dirichlet)\n",
    "        loss_neumann = loss_neumann_boundary(model, boundary_points_neumann, axis='horizontal')\n",
    "\n",
    "        # Add other boundary losses if needed\n",
    "        total_loss = loss_laplace + boundary_loss_dirichlet + loss_neumann\n",
    "        \n",
    "        total_loss.backward()  # Compute gradients\n",
    "        return total_loss\n",
    "\n",
    "    # Step with LBFGS, passing in the closure\n",
    "\n",
    "    optimizer.step(closure)    \n",
    "\n",
    "    #losses\n",
    "    loss_laplace=laplace_residual(model,train_points)\n",
    "    loss_dirichlet = loss_dirichlet_boundary(model, boundary_points_dirichlet, boundary_target_dirichlet)\n",
    "    loss_neumann = loss_neumann_boundary(model, boundary_points_neumann, axis='horizontal')\n",
    "    loss=loss_laplace * lambda_laplace  + loss_dirichlet * lambda_dirichlet + loss_neumann * lambda_neumann\n",
    "    # Append losses to the lists\n",
    "    laplace_losses.append(loss_laplace.item()) \n",
    "    dirichlet_losses.append(loss_dirichlet.item())\n",
    "    neumann_losses.append(loss_neumann.item())\n",
    "    total_losses.append(loss.item())\n",
    "    epochs_recorded.append(epoch) \n",
    "\n",
    "    scheduler.step(loss)\n",
    "\n",
    "    # Logging\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Total Loss: {loss.item():.3E}, Domain Loss: {loss_laplace.item():.3E}, Boundary Loss Dirichlet: {loss_dirichlet.item():.3E}\")\n",
    "        plot_losses(epochs_recorded, laplace_losses, dirichlet_losses, neumann_losses, total_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "num = 100\n",
    "x = y = torch.linspace(0, 1, num)\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "test_points = torch.cat([X.reshape(-1, 1), Y.reshape(-1, 1)], dim=1)\n",
    "\n",
    "# Assume `model` is your trained PINN model\n",
    "\n",
    "# PINN solution\n",
    "u_predicted = model(test_points).detach().numpy().reshape(num, num)  # Convert to numpy array for plotting\n",
    "\n",
    "# Analytical solution\n",
    "u_analytical = X.numpy()  # Linear solution u(x, y) = x, independent of y\n",
    "\n",
    "# Difference between PINN solution and analytical solution\n",
    "u_difference = u_predicted - u_analytical\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: PINN Solution\n",
    "c1 = axs[0].contourf(X.numpy(), Y.numpy(), u_predicted, levels=10, cmap=\"viridis\")\n",
    "fig.colorbar(c1, ax=axs[0])\n",
    "axs[0].set_title(\"PINN Solution\")\n",
    "axs[0].set_xlabel(\"x\")\n",
    "axs[0].set_ylabel(\"y\")\n",
    "\n",
    "# Plot 2: Analytical Solution\n",
    "c2 = axs[1].contourf(X.numpy(), Y.numpy(), u_analytical, levels=10, cmap=\"viridis\")\n",
    "fig.colorbar(c2, ax=axs[1])\n",
    "axs[1].set_title(\"Analytical Solution\")\n",
    "axs[1].set_xlabel(\"x\")\n",
    "axs[1].set_ylabel(\"y\")\n",
    "\n",
    "# Plot 3: Difference (PINN - Analytical)\n",
    "c3 = axs[2].contourf(X.numpy(), Y.numpy(), u_difference, levels=40, cmap=\"coolwarm\")\n",
    "fig.colorbar(c3, ax=axs[2])\n",
    "axs[2].set_title(\"Difference (PINN - Analytical)\")\n",
    "axs[2].set_xlabel(\"x\")\n",
    "axs[2].set_ylabel(\"y\")\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to reduce whitespace\n",
    "plt.show()\n",
    "\n",
    "print(f\"Maximum absolute difference: {np.abs(u_difference).max():.3E}, Mean absolute difference: {np.abs(u_difference).mean():.3E}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
